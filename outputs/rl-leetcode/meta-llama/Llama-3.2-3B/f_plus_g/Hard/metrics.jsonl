{"progress/epoch": 0, "progress/step": 0, "optim/lr": 1e-05, "progress/done_frac": 0.022222222222222223, "time/total": 234.53244066238403, "reward/mean": 0.20761718750000002, "reward/correctness_f": 0.0025390625, "reward/compilable_g": 0.205078125, "reward/f_minus_g": -0.20253906249999998, "policy/entropy": 2.866934587543652, "step": 0, "timestamp": 1765252027.3211617}
{"progress/epoch": 0, "progress/step": 1, "optim/lr": 1e-05, "progress/done_frac": 0.044444444444444446, "time/total": 242.72962045669556, "reward/mean": 0.215625, "reward/correctness_f": 0.00078125, "reward/compilable_g": 0.21484375, "reward/f_minus_g": -0.2140625, "policy/entropy": 2.8011162473203206, "step": 1, "timestamp": 1765252270.0663474}
{"progress/epoch": 0, "progress/step": 2, "optim/lr": 1e-05, "progress/done_frac": 0.06666666666666667, "time/total": 243.6194887161255, "reward/mean": 0.247265625, "reward/correctness_f": 0.0011718750000000002, "reward/compilable_g": 0.24609375, "reward/f_minus_g": -0.244921875, "policy/entropy": 2.718194471396181, "step": 2, "timestamp": 1765252513.7009995}
{"progress/epoch": 0, "progress/step": 3, "optim/lr": 1e-05, "progress/done_frac": 0.08888888888888889, "time/total": 227.59608125686646, "reward/mean": 0.189453125, "reward/correctness_f": 0.0, "reward/compilable_g": 0.189453125, "reward/f_minus_g": -0.189453125, "policy/entropy": 2.778271105423481, "step": 3, "timestamp": 1765252741.3129165}
{"progress/epoch": 0, "progress/step": 4, "optim/lr": 1e-05, "progress/done_frac": 0.1111111111111111, "time/total": 224.3391785621643, "reward/mean": 0.19140625, "reward/correctness_f": 0.0, "reward/compilable_g": 0.19140625, "reward/f_minus_g": -0.19140625, "policy/entropy": 2.757440605321207, "step": 4, "timestamp": 1765252965.665225}
{"progress/epoch": 0, "progress/step": 5, "optim/lr": 1e-05, "progress/done_frac": 0.13333333333333333, "time/total": 234.35601902008057, "reward/mean": 0.22734375, "reward/correctness_f": 0.00078125, "reward/compilable_g": 0.2265625, "reward/f_minus_g": -0.22578125, "policy/entropy": 2.6813773768484728, "step": 5, "timestamp": 1765253200.036587}
{"progress/epoch": 0, "progress/step": 6, "optim/lr": 1e-05, "progress/done_frac": 0.15555555555555556, "time/total": 238.04786205291748, "reward/mean": 0.240234375, "reward/correctness_f": 0.0, "reward/compilable_g": 0.240234375, "reward/f_minus_g": -0.240234375, "policy/entropy": 2.586795623320933, "step": 6, "timestamp": 1765253438.1030664}
{"progress/epoch": 0, "progress/step": 7, "optim/lr": 1e-05, "progress/done_frac": 0.17777777777777778, "time/total": 236.86715149879456, "reward/mean": 0.24492187499999998, "reward/correctness_f": 0.004687499999999999, "reward/compilable_g": 0.240234375, "reward/f_minus_g": -0.23554687500000002, "policy/entropy": 2.752524896919541, "step": 7, "timestamp": 1765253674.9831033}
{"progress/epoch": 0, "progress/step": 8, "optim/lr": 1e-05, "progress/done_frac": 0.2, "time/total": 244.10732436180115, "reward/mean": 0.224609375, "reward/correctness_f": 0.0, "reward/compilable_g": 0.224609375, "reward/f_minus_g": -0.224609375, "policy/entropy": 2.749694618215829, "step": 8, "timestamp": 1765253919.1030061}
{"progress/epoch": 1, "progress/step": 9, "optim/lr": 1e-05, "progress/done_frac": 0.2222222222222222, "time/total": 236.77639842033386, "reward/mean": 0.2169921875, "reward/correctness_f": 0.0021484375, "reward/compilable_g": 0.21484375, "reward/f_minus_g": -0.2126953125, "policy/entropy": 2.739426540682992, "step": 9, "timestamp": 1765254155.896946}
{"progress/epoch": 1, "progress/step": 10, "optim/lr": 1e-05, "progress/done_frac": 0.24444444444444444, "time/total": 304.07760548591614, "reward/mean": 0.240625, "reward/correctness_f": 0.000390625, "reward/compilable_g": 0.240234375, "reward/f_minus_g": -0.23984375, "policy/entropy": 2.6810055046868184, "step": 10, "timestamp": 1765254459.9887428}
{"progress/epoch": 1, "progress/step": 11, "optim/lr": 1e-05, "progress/done_frac": 0.26666666666666666, "time/total": 260.33474135398865, "reward/mean": 0.25078125, "reward/correctness_f": 0.00078125, "reward/compilable_g": 0.25, "reward/f_minus_g": -0.24921875, "policy/entropy": 2.7123372982495306, "step": 11, "timestamp": 1765254720.3367217}
